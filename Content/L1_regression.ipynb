{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L1 regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook presents some theoretical developments for deducing the Iteratively Reweighted Least Squares (IRLS)  (Scales and Gersztenkorn, 1988; Aster et al., 2019, p. 46)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "* Scales, J. A., and Gersztenkorn, A. 1988. *Robust methods in inverse theory*, **Inverse Problems**, 4(4), 1071-1091, doi: <a href=\"https://doi.org/10.1088%2F0266-5611%2F4%2F4%2F010\" target=\"_blank\">10.1088/0266-5611/4/4/010</a>\n",
    "\n",
    "* Aster, R. C., Borchers, B., and Thurber, C. H. Parameter Estimation and Inverse Problems, 3rd edition Elsevier Academic Press, 2019, ISBN: 978-0-12-804651-7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ordinary least squares solutions are adversely affected by outliers since the large deviations are averaged into the solution. On the other hand, least-absolute deviation optimization is known to be resistant to certain (potentially large) errors in the data. So, as an alternative to least squares in the presence of outliers, consider the solution that minimizes the $\\ell_{1}$-norm of the residuals vector (Scales and Gersztenkorn, 1988; Aster et al., 2019, p. 46),"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='eq1'></a>\n",
    "$$\n",
    "\\Phi_{abs}(\\mathbf{p}) = \\sum\\limits_{i = 0}^{N-1} \\mid r_{i} \\mid \\quad , \\tag{1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $r_{i}$ is the $i$th element of the residuals vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='eq2'></a>\n",
    "$$\n",
    "\\mathbf{r} = \\mathbf{d} - \\mathbf{A} \\mathbf{p} \\quad . \\tag{2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameter vector $\\acute{\\mathbf{p}}$ minimizing the function $\\Phi_{abs}(\\mathbf{p})$ ([equation 1](#eq1)) is less affected by outliers and, because of that, it is considered a *robust* solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By following the same reasoning presented for ordinary least squares (notebook `least_squares`) and weighted least squares (notebook `weighted_least_squares`), we start our investigation about the solution $\\acute{\\mathbf{p}}$ by computing the $j$th element of the gradient of $\\Phi_{abs}(\\mathbf{p})$ ([equation 1](#eq1)):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "<a id='eq3'></a>\n",
    "$$\n",
    "\\begin{split}\n",
    "\\dfrac{\\partial \\, \\Phi_{abs}(\\mathbf{p})}{\\partial \\, p_{j}} \n",
    "&= \\sum\\limits_{i = 0}^{N-1} \\frac{r_{i}}{\\mid r_{i} \\mid} \\left( - a_{ij} \\right) \\\\\n",
    "&= - \\mathbf{u}_{j}^{\\top} \\mathbf{A}^{\\top} \\mathbf{R} \\left( \\mathbf{d} - \\mathbf{A} \\mathbf{p} \\right)\n",
    "\\end{split} \\quad , \\tag{3}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $\\mathbf{u}_{j}$ is a $M \\times 1$ vector whose $j$ th element is equal to $1$ and all the remaining elements are equal to $0$ and "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='eq4'></a>\n",
    "$$\n",
    "\\mathbf{R} = \\begin{bmatrix}\n",
    "\\frac{1}{\\mid r_{0} \\mid} & & \\\\\n",
    "& \\ddots & \\\\\n",
    "& & \\frac{1}{\\mid r_{N-1} \\mid}\n",
    "\\end{bmatrix} \\quad . \\tag{4}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using the derivative defined by [equation 3](#eq3), we obtain the gradient of $\\Phi_{abs}(\\mathbf{p})$ ([equation 1](#eq1)) given by:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='eq5'></a>\n",
    "$$\n",
    "\\nabla \\Phi_{abs}(\\mathbf{p}) = - \\mathbf{A}^{\\top} \\mathbf{R} \\left( \\mathbf{d} - \\mathbf{A}\\mathbf{p} \\right) \\: . \\tag{5}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, by evaluating the gradient $\\nabla \\Phi_{abs}(\\mathbf{p})$ ([equation 5](#eq5)) at $\\mathbf{p} = \\acute{\\mathbf{p}}$, we obtain "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='eq6'></a>\n",
    "$$\n",
    "\\begin{align}\n",
    "\\nabla \\Phi_{abs}(\\acute{\\mathbf{p}}) &= - \\mathbf{A}^{\\top} \\mathbf{R} \\left( \\mathbf{d} - \\mathbf{A}\\acute{\\mathbf{p}} \\right) \\\\\n",
    "\\mathbf{0} &= -\\mathbf{A}^{\\top} \\mathbf{R} \\mathbf{d} + \\mathbf{A}^{\\top} \\mathbf{R} \\mathbf{A}\\acute{\\mathbf{p}}\n",
    "\\end{align} \\tag{6}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "resulting that"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='eq7'></a>\n",
    "$$\n",
    "\\left( \\mathbf{A}^{\\top} \\mathbf{R} \\mathbf{A} \\right) \\acute{\\mathbf{p}} = \\mathbf{A}^{\\top} \\mathbf{R} \\, \\mathbf{d} \\quad . \\tag{7}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As $\\mathbf{R}$ depends on the residuals, this equation must be used iteratively. This equation represents one iteration of the **IRLS** method (Scales and Gersztenkorn, 1988; Aster et al., 2019, p. 46)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method starts with $\\mathbf{R} = \\mathbf{I}$, which results in an ordinary least-squares solution $\\mathbf{p}_{0}$. This solution is used to compute the first residuals vector $\\mathbf{r}_{0}$ and the matrix $\\mathbf{R}_{0}$. Then, [equation 7](#eq7) is solved to obtain a new vector $\\mathbf{p}_{1}$, which is used for computing a new residuals vector $\\mathbf{r}_{1}$ and a matrix $\\mathbf{R}_{1}$. This process is commonly repeated until the following criterion be satisfied (Aster et al., 2019, p. 47):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='eq8'></a>\n",
    "$$\n",
    "\\frac{\\| \\mathbf{p}_{k} - \\mathbf{p}_{k-1} \\|_{2}}{1 + \\| \\mathbf{p}_{k} \\|_{2}} < \\tau \\quad , \\tag{8}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $\\tau$ is a specified tolerance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating the uncertainty of the parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A way of propagating the uncertainties from data to the estimated parameters in the IRLS method is the Monte Carlo error propagation (Aster et al., 2019, p. 48). In this method, the first steps consists in obtaining an IRLS solution $\\acute{\\mathbf{p}}$. Then, a set of IRLS solutions $\\acute{\\mathbf{p}}_{q}$, $q = 0, \\dots, Q-1$, is obtained by using different noise realizations to contaminate the observed data. A $Q \\times M$ matrix $\\mathbf{C}$ is formed by rows $\\mathbf{c}_{q} = \\acute{\\mathbf{p}}_{q} - \\acute{\\mathbf{p}}$. Finally, an empirical estimate of the covariance matrix $\\boldsymbol{\\Sigma}_{\\acute{\\mathbf{p}}}$ is obtained in this fashion:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='eq9'></a>\n",
    "$$\n",
    "\\boldsymbol{\\Sigma}_{\\acute{\\mathbf{p}}} = \\frac{\\mathbf{C}^{\\top}\\mathbf{C}}{Q} \\quad . \\tag{9}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
